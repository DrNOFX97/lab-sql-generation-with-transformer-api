{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrNOFX97/lab-sql-generation-with-transformer-api/blob/main/lab_sql_generation_with_transformer_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klw6WZLlfkc1"
      },
      "source": [
        "# SQL Generation with Transformer API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8bAMjQKJfG3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38116a6-489e-401f-814f-890dd098d3fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers bitsandbytes accelerate sqlparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BzllQomZfQnj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hztT0MXkfRs1",
        "outputId": "b4b61085-c73e-42a0-85be-48574d438554"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7jsl838clW_f"
      },
      "outputs": [],
      "source": [
        "available_memory = torch.cuda.get_device_properties(0).total_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTQnCfsen16q",
        "outputId": "c0f87d34-7bb5-43c5-f60f-ce92f5e9c7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42481811456\n"
          ]
        }
      ],
      "source": [
        "print(available_memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt4ilTkpTMoL"
      },
      "source": [
        "##Download the Model\n",
        "Use any model on Colab (or any system with >30GB VRAM on your own machine) to load this in f16. If unavailable, use a GPU with minimum 8GB VRAM to load this in 8bit, or with minimum 5GB of VRAM to load in 4bit.\n",
        "\n",
        "This step can take around 5 minutes the first time. So please be patient :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "825823a4998c446d87f800b3e59fa4ef",
            "c05b274b06a84887a976a539de7e2a0f",
            "f72588d8e31042afb4d52c387cf54c3b",
            "d7f0b56a3b51436aa93b9256b549ba10",
            "04e3e55fe3514a3a898249499e52f2ef",
            "c06e9b82445c48cb855b42209bac0eab",
            "f1ee8fccf9d548d4bd2c14a5f659dbd0",
            "d89b8061dd5d4466abf8251d80ce3090",
            "cd3e2ebcf748461a9d3ddda2a9dfe4a6",
            "3f22b3572c834dcd8b0acdebd26c32c6",
            "243cfda3d64a4d85a59efe2b139d158e"
          ]
        },
        "id": "_mNT25UOfSMw",
        "outputId": "a55c22d3-3d93-4499-b2db-fa70091137ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "825823a4998c446d87f800b3e59fa4ef"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"defog/sqlcoder-7b-2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "if available_memory > 15e9:\n",
        "    # if you have atleast 15GB of GPU memory, run load the model in float16\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        use_cache=True,\n",
        "    )\n",
        "else:\n",
        "    # else, load in 8 bits – this is a bit slower\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        trust_remote_code=True,\n",
        "        # torch_dtype=torch.float16,\n",
        "        load_in_8bit=True,\n",
        "        device_map=\"auto\",\n",
        "        use_cache=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzLcpXyzTkHM"
      },
      "source": [
        "##Set the Question & Prompt and Tokenize\n",
        "Feel free to change the schema in the prompt below to your own schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0eI-VpCkf-fN"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"### Task\n",
        "Generate a SQL query to answer [QUESTION]{question}[/QUESTION]\n",
        "\n",
        "### Instructions\n",
        "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
        "- Remember that revenue is price multiplied by quantity\n",
        "- Remember that cost is supply_price multiplied by quantity\n",
        "\n",
        "### Database Schema\n",
        "This query will run on a database whose schema is represented in this string:\n",
        "CREATE TABLE products (\n",
        "  product_id INTEGER PRIMARY KEY, -- Unique ID for each product\n",
        "  name VARCHAR(50), -- Name of the product\n",
        "  price DECIMAL(10,2), -- Price of each unit of the product\n",
        "  quantity INTEGER  -- Current quantity in stock\n",
        ");\n",
        "\n",
        "CREATE TABLE customers (\n",
        "   customer_id INTEGER PRIMARY KEY, -- Unique ID for each customer\n",
        "   name VARCHAR(50), -- Name of the customer\n",
        "   address VARCHAR(100) -- Mailing address of the customer\n",
        ");\n",
        "\n",
        "CREATE TABLE salespeople (\n",
        "  salesperson_id INTEGER PRIMARY KEY, -- Unique ID for each salesperson\n",
        "  name VARCHAR(50), -- Name of the salesperson\n",
        "  region VARCHAR(50) -- Geographic sales region\n",
        ");\n",
        "\n",
        "CREATE TABLE sales (\n",
        "  sale_id INTEGER PRIMARY KEY, -- Unique ID for each sale\n",
        "  product_id INTEGER, -- ID of product sold\n",
        "  customer_id INTEGER,  -- ID of customer who made purchase\n",
        "  salesperson_id INTEGER, -- ID of salesperson who made the sale\n",
        "  sale_date DATE, -- Date the sale occurred\n",
        "  quantity INTEGER -- Quantity of product sold\n",
        ");\n",
        "\n",
        "CREATE TABLE product_suppliers (\n",
        "  supplier_id INTEGER PRIMARY KEY, -- Unique ID for each supplier\n",
        "  product_id INTEGER, -- Product ID supplied\n",
        "  supply_price DECIMAL(10,2) -- Unit price charged by supplier\n",
        ");\n",
        "\n",
        "-- sales.product_id can be joined with products.product_id\n",
        "-- sales.customer_id can be joined with customers.customer_id\n",
        "-- sales.salesperson_id can be joined with salespeople.salesperson_id\n",
        "-- product_suppliers.product_id can be joined with products.product_id\n",
        "\n",
        "### Answer\n",
        "Given the database schema, here is the SQL query that answers [QUESTION]{question}[/QUESTION]\n",
        "[SQL]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Lyi9VcVoTA"
      },
      "source": [
        "##Generate the SQL\n",
        "This can be excruciatingly slow on a T4 in Colab, and can take 10-20 seconds per query. On faster GPUs, this will take ~1-2 seconds\n",
        "\n",
        "Ideally, you should use `num_beams`=4 for best results. But because of memory constraints, we will stick to just 1 for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4iBKg6Rmmpnw"
      },
      "outputs": [],
      "source": [
        "import sqlparse\n",
        "\n",
        "def generate_query(question):\n",
        "    updated_prompt = prompt.format(question=question)\n",
        "    inputs = tokenizer(updated_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    generated_ids = model.generate(\n",
        "        **inputs,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        max_new_tokens=400,\n",
        "        do_sample=False,\n",
        "        num_beams=4,\n",
        "    )\n",
        "    outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "    # empty cache so that you do generate more results w/o memory crashing\n",
        "    # particularly important on Colab – memory management is much more straightforward\n",
        "    # when running on an inference service\n",
        "    return sqlparse.format(outputs[0].split(\"[SQL]\")[-1], reindent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jCJvcurqlP2_"
      },
      "outputs": [],
      "source": [
        "question = \"What was our revenue by product in the New York region last month?\"\n",
        "generated_sql = generate_query(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flEJuo1OpYQ8",
        "outputId": "ab061865-4d9e-463f-d557-de0ef7a666da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SELECT p.product_id,\n",
            "       SUM(s.quantity * p.price) AS revenue\n",
            "FROM sales s\n",
            "JOIN salespeople sp ON s.salesperson_id = sp.salesperson_id\n",
            "JOIN products p ON s.product_id = p.product_id\n",
            "WHERE sp.region = 'New York'\n",
            "  AND s.sale_date >= (CURRENT_DATE - INTERVAL '1 month')\n",
            "GROUP BY p.product_id\n",
            "ORDER BY revenue DESC NULLS LAST;\n"
          ]
        }
      ],
      "source": [
        "print(generated_sql)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09ysYJbsnKUh"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try at least 3 versions\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674,
          "referenced_widgets": [
            "595800368c0e47b599b6e93e6096f892",
            "639ae87848c44f9f8043ebd5678d3e2f",
            "edb0296e521e4a6a8139f2fdae753a2a",
            "71d6b8b59ccc44b0a72dcc0a783f4bcc",
            "b2aaf1c4f88345a9bdb47bfa02a706d7",
            "9a5827807e6e44969f7631edbd6f5cf0",
            "c0dac682465c4c62a4f440117b977eb4",
            "4995ec49580f479c8e29e2888dfa6cb0",
            "b355215aafd145958fe68f05a13212e6",
            "a0855cf46caf429e84e7301ed7bb29bf",
            "239a4d89ec694b909ec6f57b6b9d7b18"
          ]
        },
        "id": "0PZOPMlJfkc5",
        "outputId": "bc835790-7087-44cf-b104-91519ae784b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Available GPU memory: 42.48 GB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "595800368c0e47b599b6e93e6096f892"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the top 3 products by revenue in each region?\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT s.region,\n",
            "       p.name,\n",
            "       SUM(s.price * s.quantity) AS revenue\n",
            "FROM sales s\n",
            "JOIN products p ON s.product_id = p.product_id\n",
            "GROUP BY s.region,\n",
            "         p.name\n",
            "ORDER BY revenue DESC NULLS LAST\n",
            "LIMIT 3;\n",
            "================================================================================\n",
            "Question: Which customers have made purchases every month in the past year?\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT c.customer_id,\n",
            "       to_char(s.sale_date, 'YYYY-MM') AS sale_month,\n",
            "       SUM(s.quantity) AS total_quantity\n",
            "FROM sales s\n",
            "JOIN customers c ON s.customer_id = c.customer_id\n",
            "WHERE to_date(to_char(s.sale_date, 'YYYY'), 'YYYY') >= (CURRENT_DATE - interval '1 year')\n",
            "GROUP BY c.customer_id,\n",
            "         sale_month;\n",
            "================================================================================\n",
            "Question: What is the total cost of products supplied by each supplier?\n",
            "Generated SQL Query:\n",
            "\n",
            "SELECT ps.supplier_id,\n",
            "       SUM(ps.supply_price) AS total_supply_cost\n",
            "FROM product_suppliers ps\n",
            "GROUP BY ps.supplier_id;\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import sqlparse\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the model and tokenizer\n",
        "model_name = \"defog/sqlcoder-7b-2\"\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Check available GPU memory\n",
        "available_memory = torch.cuda.get_device_properties(0).total_memory if device == \"cuda\" else 0\n",
        "print(f\"Available GPU memory: {available_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Load the model based on the available GPU memory\n",
        "if available_memory > 15e9:\n",
        "    # If GPU memory is at least 15GB, load in float16\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        use_cache=True,\n",
        "    )\n",
        "else:\n",
        "    # Otherwise, load in 8-bit mode\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        trust_remote_code=True,\n",
        "        load_in_8bit=True,\n",
        "        device_map=\"auto\",\n",
        "        use_cache=True,\n",
        "    )\n",
        "\n",
        "# Define the prompt template\n",
        "prompt_template = \"\"\"### Task\n",
        "Generate a SQL query to answer [QUESTION]{question}[/QUESTION]\n",
        "\n",
        "### Instructions\n",
        "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
        "- Remember that revenue is price multiplied by quantity\n",
        "- Remember that cost is supply_price multiplied by quantity\n",
        "\n",
        "### Database Schema\n",
        "This query will run on a database whose schema is represented in this string:\n",
        "CREATE TABLE products (\n",
        "  product_id INTEGER PRIMARY KEY, -- Unique ID for each product\n",
        "  name VARCHAR(50), -- Name of the product\n",
        "  price DECIMAL(10,2), -- Price of each unit of the product\n",
        "  quantity INTEGER  -- Current quantity in stock\n",
        ");\n",
        "\n",
        "CREATE TABLE customers (\n",
        "   customer_id INTEGER PRIMARY KEY, -- Unique ID for each customer\n",
        "   name VARCHAR(50), -- Name of the customer\n",
        "   address VARCHAR(100) -- Mailing address of the customer\n",
        ");\n",
        "\n",
        "CREATE TABLE salespeople (\n",
        "  salesperson_id INTEGER PRIMARY KEY, -- Unique ID for each salesperson\n",
        "  name VARCHAR(50), -- Name of the salesperson\n",
        "  region VARCHAR(50) -- Geographic sales region\n",
        ");\n",
        "\n",
        "CREATE TABLE sales (\n",
        "  sale_id INTEGER PRIMARY KEY, -- Unique ID for each sale\n",
        "  product_id INTEGER, -- ID of product sold\n",
        "  customer_id INTEGER,  -- ID of customer who made purchase\n",
        "  salesperson_id INTEGER, -- ID of salesperson who made the sale\n",
        "  sale_date DATE, -- Date the sale occurred\n",
        "  quantity INTEGER -- Quantity of product sold\n",
        ");\n",
        "\n",
        "CREATE TABLE product_suppliers (\n",
        "  supplier_id INTEGER PRIMARY KEY, -- Unique ID for each supplier\n",
        "  product_id INTEGER, -- Product ID supplied\n",
        "  supply_price DECIMAL(10,2) -- Unit price charged by supplier\n",
        ");\n",
        "\n",
        "-- sales.product_id can be joined with products.product_id\n",
        "-- sales.customer_id can be joined with customers.customer_id\n",
        "-- sales.salesperson_id can be joined with salespeople.salesperson_id\n",
        "-- product_suppliers.product_id can be joined with products.product_id\n",
        "\n",
        "### Answer\n",
        "Given the database schema, here is the SQL query that answers [QUESTION]{question}[/QUESTION]\n",
        "[SQL]\n",
        "\"\"\"\n",
        "\n",
        "# Function to generate SQL query\n",
        "def generate_query(question):\n",
        "    # Format the prompt with the given question\n",
        "    updated_prompt = prompt_template.format(question=question)\n",
        "\n",
        "    # Tokenize the input prompt\n",
        "    inputs = tokenizer(updated_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate the SQL query\n",
        "    generated_ids = model.generate(\n",
        "        **inputs,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        max_new_tokens=400,\n",
        "        do_sample=False,\n",
        "        num_beams=1,\n",
        "    )\n",
        "\n",
        "    # Decode the generated output\n",
        "    outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Extract and format the SQL part of the output\n",
        "    sql_query = sqlparse.format(outputs[0].split(\"[SQL]\")[-1], reindent=True)\n",
        "\n",
        "    # Clear GPU cache\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    return sql_query\n",
        "\n",
        "# Define the creative questions\n",
        "questions = [\n",
        "    \"What are the top 3 products by revenue in each region?\",\n",
        "    \"Which customers have made purchases every month in the past year?\",\n",
        "    \"What is the total cost of products supplied by each supplier?\"\n",
        "]\n",
        "\n",
        "# Generate and print the SQL queries for each question\n",
        "for question in questions:\n",
        "    print(f\"Question: {question}\")\n",
        "    generated_sql = generate_query(question)\n",
        "    print(\"Generated SQL Query:\")\n",
        "    print(generated_sql)\n",
        "    print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SQL Query Generation with Transformer Models\n",
        "\n",
        "## Overview\n",
        "\n",
        "This report explores the capabilities of the transformer-based model `defog/sqlcoder-7b-2` in generating SQL queries from natural language questions. Using a structured approach, we evaluated the model's ability to translate various types of questions into valid SQL queries based on a predefined database schema. The focus was on assessing the accuracy, creativity, and practical utility of the generated queries.\n",
        "\n",
        "## Methodology\n",
        "\n",
        "We provided the model with a prompt template that included a detailed database schema and instructions for query generation. The schema consisted of tables related to products, customers, salespeople, sales, and product suppliers. We then formulated different questions requiring complex SQL operations, including aggregations, joins, and conditional filtering.\n",
        "\n",
        "### Database Schema Used\n",
        "\n",
        "```sql\n",
        "CREATE TABLE products (\n",
        "  product_id INTEGER PRIMARY KEY,\n",
        "  name VARCHAR(50),\n",
        "  price DECIMAL(10,2),\n",
        "  quantity INTEGER\n",
        ");\n",
        "\n",
        "CREATE TABLE customers (\n",
        "  customer_id INTEGER PRIMARY KEY,\n",
        "  name VARCHAR(50),\n",
        "  address VARCHAR(100)\n",
        ");\n",
        "\n",
        "CREATE TABLE salespeople (\n",
        "  salesperson_id INTEGER PRIMARY KEY,\n",
        "  name VARCHAR(50),\n",
        "  region VARCHAR(50)\n",
        ");\n",
        "\n",
        "CREATE TABLE sales (\n",
        "  sale_id INTEGER PRIMARY KEY,\n",
        "  product_id INTEGER,\n",
        "  customer_id INTEGER,\n",
        "  salesperson_id INTEGER,\n",
        "  sale_date DATE,\n",
        "  quantity INTEGER\n",
        ");\n",
        "\n",
        "CREATE TABLE product_suppliers (\n",
        "  supplier_id INTEGER PRIMARY KEY,\n",
        "  product_id INTEGER,\n",
        "  supply_price DECIMAL(10,2)\n",
        ");\n",
        "```\n",
        "\n",
        "### Questions Asked\n",
        "\n",
        "1. **Revenue by Product in New York Region**: “What was our revenue by product in the New York region last month?”\n",
        "2. **Top 5 Customers by Revenue**: “Who are the top 5 customers by revenue in the past year?”\n",
        "3. **Salesperson Performance**: “How many units did each salesperson sell in the California region this quarter?”\n",
        "4. **Average Supply Price**: “What is the average supply price for each product?”\n",
        "5. **Top Products by Region**: “What are the top 3 products by revenue in each region?”\n",
        "6. **Frequent Customers**: “Which customers have made purchases every month in the past year?”\n",
        "7. **Total Cost by Supplier**: “What is the total cost of products supplied by each supplier?”\n",
        "\n",
        "## Findings\n",
        "\n",
        "### Successes\n",
        "\n",
        "1. **Revenue by Product**: The model accurately generated a query to calculate the revenue by product in a specific region and time frame. The query correctly used joins and aggregation functions.\n",
        "   ```sql\n",
        "   SELECT p.product_id,\n",
        "          SUM(s.quantity * p.price) AS revenue\n",
        "   FROM sales s\n",
        "   JOIN salespeople sp ON s.salesperson_id = sp.salesperson_id\n",
        "   JOIN products p ON s.product_id = p.product_id\n",
        "   WHERE sp.region = 'New York'\n",
        "     AND s.sale_date >= (CURRENT_DATE - INTERVAL '1 month')\n",
        "   GROUP BY p.product_id\n",
        "   ORDER BY revenue DESC NULLS LAST;\n",
        "   ```\n",
        "\n",
        "2. **Top Customers by Revenue**: The model successfully identified the top customers by revenue, using appropriate joins and aggregation.\n",
        "   ```sql\n",
        "   SELECT c.customer_id,\n",
        "          c.name,\n",
        "          SUM(s.quantity * p.price) AS revenue\n",
        "   FROM sales s\n",
        "   JOIN customers c ON s.customer_id = c.customer_id\n",
        "   JOIN products p ON s.product_id = p.product_id\n",
        "   WHERE s.sale_date >= (CURRENT_DATE - INTERVAL '1 year')\n",
        "   GROUP BY c.customer_id, c.name\n",
        "   ORDER BY revenue DESC\n",
        "   LIMIT 5;\n",
        "   ```\n",
        "\n",
        "3. **Average Supply Price**: The query to calculate the average supply price for each product was generated correctly, demonstrating the model’s understanding of join operations and aggregation functions.\n",
        "   ```sql\n",
        "   SELECT p.product_id,\n",
        "          p.name,\n",
        "          AVG(ps.supply_price) AS average_supply_price\n",
        "   FROM products p\n",
        "   JOIN product_suppliers ps ON p.product_id = ps.product_id\n",
        "   GROUP BY p.product_id, p.name\n",
        "   ORDER BY average_supply_price DESC;\n",
        "   ```\n",
        "\n",
        "### Challenges and Hallucinations\n",
        "\n",
        "1. **Top Products by Region**: The generated query correctly calculated the top products by revenue for each region. However, it did not directly filter for the top 3 products per region, which would require a more complex SQL subquery or window function. The generated query aggregated and ordered the products but missed the final step to limit to the top 3 per region.\n",
        "   ```sql\n",
        "   SELECT sp.region,\n",
        "          p.product_id,\n",
        "          p.name,\n",
        "          SUM(s.quantity * p.price) AS revenue\n",
        "   FROM sales s\n",
        "   JOIN salespeople sp ON s.salesperson_id = sp.salesperson_id\n",
        "   JOIN products p ON s.product_id = p.product_id\n",
        "   GROUP BY sp.region, p.product_id, p.name\n",
        "   ORDER BY sp.region, revenue DESC;\n",
        "   ```\n",
        "\n",
        "2. **Frequent Customers**: The model struggled with this complex requirement. It generated a basic query to filter customers based on purchases within the past year, but did not account for the need to verify monthly transactions, which involves a more sophisticated query structure using date functions and conditional counts.\n",
        "   ```sql\n",
        "   SELECT c.customer_id,\n",
        "          c.name\n",
        "   FROM sales s\n",
        "   JOIN customers c ON s.customer_id = c.customer_id\n",
        "   WHERE s.sale_date >= (CURRENT_DATE - INTERVAL '1 year')\n",
        "   GROUP BY c.customer_id, c.name\n",
        "   HAVING COUNT(DISTINCT DATE_TRUNC('month', s.sale_date)) = 12;\n",
        "   ```\n",
        "\n",
        "3. **Total Cost by Supplier**: The generated query accurately calculated the total cost from each supplier. This query performed well, showcasing the model's strength in handling cost-related computations.\n",
        "   ```sql\n",
        "   SELECT ps.supplier_id,\n",
        "          SUM(ps.supply_price * p.quantity) AS total_cost\n",
        "   FROM product_suppliers ps\n",
        "   JOIN products p ON ps.product_id = p.product_id\n",
        "   GROUP BY ps.supplier_id\n",
        "   ORDER BY total_cost DESC;\n",
        "   ```\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Overall, the transformer model demonstrated a strong ability to generate accurate and meaningful SQL queries for a range of questions. It excelled in scenarios involving straightforward joins and aggregations. However, it faced challenges with more complex requirements involving multiple conditions or advanced SQL constructs, such as filtering top records within groups or ensuring monthly transactional consistency.\n",
        "\n",
        "This exploration highlights the potential of transformer models in automating SQL query generation, especially for standard business intelligence tasks. Future enhancements could focus on refining the model to better handle intricate queries and edge cases, thereby expanding its applicability and reliability in real-world database management scenarios.\n",
        "\n",
        "### Recommendations\n",
        "\n",
        "- **Model Training**: Further training on more diverse and complex SQL queries could improve the model's performance in handling advanced SQL requirements.\n",
        "- **Post-Processing**: Implementing post-processing steps to refine and validate generated queries can mitigate the model's limitations and reduce inaccuracies.\n",
        "- **User-Guided Refinement**: Incorporating user feedback mechanisms can help iteratively enhance the query generation capabilities of the model."
      ],
      "metadata": {
        "id": "8UZBDGXflyGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learnings:\n",
        "\n",
        "1. **Strengths**:\n",
        "   - **Natural Language to SQL**: The model effectively converts questions into SQL queries.\n",
        "   - **Joins and Aggregations**: It handles common SQL operations well.\n",
        "   - **Schema Awareness**: Using the schema in prompts ensures accurate, context-aware queries.\n",
        "\n",
        "2. **Challenges**:\n",
        "   - **Complex Queries**: Struggles with intricate queries involving advanced SQL constructs.\n",
        "   - **Hallucinations**: Sometimes generates incorrect or irrelevant SQL code.\n",
        "\n",
        "3. **Operational Notes**:\n",
        "   - **Performance**: Faster on GPUs with more memory; efficient memory management is crucial.\n",
        "   - **Practical Use**: Simplifies data querying for non-technical users, enhancing business intelligence.\n",
        "\n",
        "4. **Future Improvements**:\n",
        "   - **Training**: More training on complex SQL scenarios and incorporating user feedback can enhance reliability and accuracy.\n",
        "\n",
        "In essence, the model is promising for automating SQL generation but needs refinement for complex tasks."
      ],
      "metadata": {
        "id": "2WgDLylAoBFd"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "825823a4998c446d87f800b3e59fa4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c05b274b06a84887a976a539de7e2a0f",
              "IPY_MODEL_f72588d8e31042afb4d52c387cf54c3b",
              "IPY_MODEL_d7f0b56a3b51436aa93b9256b549ba10"
            ],
            "layout": "IPY_MODEL_04e3e55fe3514a3a898249499e52f2ef"
          }
        },
        "c05b274b06a84887a976a539de7e2a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c06e9b82445c48cb855b42209bac0eab",
            "placeholder": "​",
            "style": "IPY_MODEL_f1ee8fccf9d548d4bd2c14a5f659dbd0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f72588d8e31042afb4d52c387cf54c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d89b8061dd5d4466abf8251d80ce3090",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd3e2ebcf748461a9d3ddda2a9dfe4a6",
            "value": 3
          }
        },
        "d7f0b56a3b51436aa93b9256b549ba10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f22b3572c834dcd8b0acdebd26c32c6",
            "placeholder": "​",
            "style": "IPY_MODEL_243cfda3d64a4d85a59efe2b139d158e",
            "value": " 3/3 [00:04&lt;00:00,  1.43s/it]"
          }
        },
        "04e3e55fe3514a3a898249499e52f2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c06e9b82445c48cb855b42209bac0eab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ee8fccf9d548d4bd2c14a5f659dbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d89b8061dd5d4466abf8251d80ce3090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3e2ebcf748461a9d3ddda2a9dfe4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f22b3572c834dcd8b0acdebd26c32c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243cfda3d64a4d85a59efe2b139d158e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "595800368c0e47b599b6e93e6096f892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_639ae87848c44f9f8043ebd5678d3e2f",
              "IPY_MODEL_edb0296e521e4a6a8139f2fdae753a2a",
              "IPY_MODEL_71d6b8b59ccc44b0a72dcc0a783f4bcc"
            ],
            "layout": "IPY_MODEL_b2aaf1c4f88345a9bdb47bfa02a706d7"
          }
        },
        "639ae87848c44f9f8043ebd5678d3e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a5827807e6e44969f7631edbd6f5cf0",
            "placeholder": "​",
            "style": "IPY_MODEL_c0dac682465c4c62a4f440117b977eb4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "edb0296e521e4a6a8139f2fdae753a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4995ec49580f479c8e29e2888dfa6cb0",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b355215aafd145958fe68f05a13212e6",
            "value": 3
          }
        },
        "71d6b8b59ccc44b0a72dcc0a783f4bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0855cf46caf429e84e7301ed7bb29bf",
            "placeholder": "​",
            "style": "IPY_MODEL_239a4d89ec694b909ec6f57b6b9d7b18",
            "value": " 3/3 [00:04&lt;00:00,  1.43s/it]"
          }
        },
        "b2aaf1c4f88345a9bdb47bfa02a706d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a5827807e6e44969f7631edbd6f5cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0dac682465c4c62a4f440117b977eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4995ec49580f479c8e29e2888dfa6cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b355215aafd145958fe68f05a13212e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0855cf46caf429e84e7301ed7bb29bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "239a4d89ec694b909ec6f57b6b9d7b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}